{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwcvVHaP5bIC"
   },
   "source": [
    "### 7.2. Approche générative (30%)\n",
    "\n",
    "Entrainez un modèle séquence à séquence de type T5 partant de la __question_raw__ et qui génére la __question_tagged__ correspondante.\n",
    "\n",
    "__Exemple:__\n",
    "\n",
    "Jeu de validation:\n",
    "\n",
    "|   question_id   |                  question_raw                          |\n",
    "|    :----:       | :----------------------------------------------:            \n",
    "|      1          | What is the country for head of state of Justin Trudeau |\n",
    "\n",
    "\n",
    "__Entrée du modèle:__ What is the country for head of state of Justin Trudeau\n",
    "\n",
    "__Prédiction du modèle__:  what is the <\\<wd:Q6256\\>> for <\\<wdt:P35\\>> of <\\<wd:Q3099714\\>>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc9-jjKV5WHw"
   },
   "source": [
    "#### 7.2.1. Modèle génératif (25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnPhKW735Yi4"
   },
   "source": [
    "Le notebook suivant est le fruit de nombreux essais pour obtenir la baseline de 25% de f1 donnée sur le moodle, elle va beaucoup plus loin que l'utilisation de base d'un T5 car celui-ci nous faisait plafonner à 7% de f1\n",
    "\n",
    "Voici la liste des solutions testées mais non présente dans ce notebook :\n",
    "- Modele Seq2Seq pretrained sur le raw pour prédire la question tagged avec differents batch size, differents ajouts de token au model (juste '<', '<' 'wd' 'wdt', 'ps' et 'pq'), ajout de toutes les classes des jetons (wd:Q362736 par exemple) en nouveau token. Ces methodes n'ont pas porté leur fruit malheuseuemnt\n",
    "- Model T5forCoditionnal avec les options citées prédédemment\n",
    "\n",
    "Le dernier model testé est un T5ForConditionnal avec une loss custom qui penalise plus les labels wikidata mal générés que le reste du texte (ce qui ressemble plus ou moins à une partie 3 mais ce n'est pas faute d'avoir essayer d'obtenir un score normal autrement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13129,
     "status": "ok",
     "timestamp": 1700947271668,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "itYJraqlOdtC",
    "outputId": "d2333fee-c2e7-4b80-9f69-215470dae94e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "# Check if CUDA is available and test it\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available? \", cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1700947271668,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "3buUBw2eOdtD",
    "outputId": "620ca06e-d765-43bc-f706-aa693503efcf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download the required NLTK resources\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2551,
     "status": "ok",
     "timestamp": 1700947274208,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "CWKNygkXvF_y",
    "outputId": "69c8640a-e0c8-49df-8d71-8ab991b9ec9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "root = '/content/drive/MyDrive/traitement du langage/TP4/data/'\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#root = './data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1700947275244,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "L8bVHBofOdtF",
    "outputId": "06ca965c-3c6a-4e88-a1e9-027bcefdb6c6"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(root+'train.csv',sep = '|')\n",
    "data_test = pd.read_csv(root+'test.csv', sep='|')\n",
    "data_validation = pd.read_csv(root+'validation.csv', sep ='|')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpAVMFm9OdtF"
   },
   "outputs": [],
   "source": [
    "regex = \"<<[wdtpsq]{2,3}:[^>]*>>\"\n",
    "all_text = data_train['question_tagged'].sum()\n",
    "list_balise = re.findall(regex, all_text)\n",
    "balises_train = Counter(list_balise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1700947278259,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "LI8rc8DCOdtF",
    "outputId": "c08a9c59-0d0d-4c1a-fe25-ee717855078f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20034\n"
     ]
    }
   ],
   "source": [
    "l_balises_train = balises_train.keys()\n",
    "print(len(l_balises_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yLhpx4gOdtH"
   },
   "outputs": [],
   "source": [
    "#return the data to the following shape : array[phrases, word of phrases], list[phrases, label of word phrases]\n",
    "def preprocess_test(df : pd.DataFrame) :\n",
    "    original_tokens = []\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['question_raw']\n",
    "        tokens = question.split()\n",
    "        original_tokens.append(tokens)\n",
    "    return original_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_5jUIceDwSx"
   },
   "outputs": [],
   "source": [
    "def retrieve_all_tags(df : pd.DataFrame) :\n",
    "    all_tags = []\n",
    "    regex = \"<<[wdtpsq]{2,3}:[^>]*>>\"\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['question_tagged']\n",
    "        tags = re.findall(regex, question)\n",
    "\n",
    "        all_tags+=tags\n",
    "\n",
    "    final_tags = list(set(all_tags))\n",
    "    return final_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLXsUcfUOdtI"
   },
   "source": [
    "Process the train and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWALnDasOdtL"
   },
   "outputs": [],
   "source": [
    "!pip install transformers -U\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTmKvWFL2hqA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, AutoTokenizer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1U0SFq2i25Pj"
   },
   "outputs": [],
   "source": [
    "def get_number_token(df) :\n",
    "    all_tags = []\n",
    "    regex = \"<<[wdtpsq]{2,3}:[PQ]([^>]*)>>\"\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['question_tagged']\n",
    "        tags = re.findall(regex, question)\n",
    "\n",
    "        all_tags+=tags\n",
    "    return list(set(all_tags))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1pCgjlc1-W-"
   },
   "source": [
    "### Implementation d'un dataset custom\n",
    "Ce dataset permet de masquer les endroits du textes ou la loss sera plus importantes si mal classifié (la ou sont les jetons wikidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xylTi-2GDwS0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=210):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.start_token_id = tokenizer.encode('<<', add_special_tokens=False)[0]\n",
    "        self.end_token_id = tokenizer.encode('>>', add_special_tokens=False)[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = \"convert to Wikidata query: \" + self.data.iloc[idx]['question_raw'] #ajout du prefix \"convert to Wikidata query : \" pour guider le modele de génération\n",
    "        target_text = self.data.iloc[idx]['question_tagged']\n",
    "\n",
    "        # Tokenizing inputs and labels\n",
    "        inputs = self.tokenizer(source_text, return_tensors=\"pt\", max_length=self.max_length, truncation=True, padding='max_length')\n",
    "        labels = self.tokenizer(target_text, return_tensors=\"pt\", max_length=self.max_length, truncation=True, padding='max_length')\n",
    "\n",
    "        # Create mask for << and >> tokens in labels\n",
    "        labels_ids = labels['input_ids'].squeeze()\n",
    "        starts = labels_ids == self.start_token_id\n",
    "        ends = labels_ids == self.end_token_id\n",
    "        ids = []\n",
    "        for i in range(len(labels_ids)):\n",
    "            ids.append(self.tokenizer.decode(labels_ids[i]))\n",
    "        # Use XOR for boolean tensors\n",
    "        cumulative = torch.cumsum(starts ^ ends, dim=-1)\n",
    "        cumulative = cumulative.masked_fill_(ends, 0)\n",
    "        cumulative =cumulative.masked_fill_(starts, 0)\n",
    "        #apply a %2 to the cumulative tensor to get the mask of all the tokens between << and >>\n",
    "        inside_brackets_mask = cumulative % 2\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': labels_ids,\n",
    "            'inside_brackets_mask': inside_brackets_mask\n",
    "        }\n",
    "\n",
    "class CustomGenDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour la génération de test\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_length=210):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = \"convert to Wikidata query: \" + self.data.iloc[idx]['question_raw']\n",
    "        # Tokenizing inputs\n",
    "        inputs = self.tokenizer(source_text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WyrHXye2dle"
   },
   "source": [
    "#### implementation de ce modele custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBSj9NO6yWdE"
   },
   "outputs": [],
   "source": [
    "class CustomT5Model(T5ForConditionalGeneration):\n",
    "    #Model custom implementant une loss differente suivant les mask des tokens entre << >>\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, inside_brackets_mask=None, pad_token_id=None,*args, **kwargs):\n",
    "        # Standard forward pass\n",
    "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, labels=labels,*args, **kwargs)\n",
    "\n",
    "        # Compute custom loss if labels and inside_brackets_mask are provided\n",
    "        if labels is not None and inside_brackets_mask is not None and pad_token_id is not None:\n",
    "            loss = self.compute_custom_loss(outputs, labels, inside_brackets_mask, pad_token_id)\n",
    "            outputs.loss = loss\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_custom_loss(model_output, labels, inside_brackets_mask, pad_token_id, inside_brackets_weight=5.0):\n",
    "        logits = model_output.logits\n",
    "        loss_fct = CrossEntropyLoss(ignore_index=pad_token_id, reduction='none')\n",
    "\n",
    "        # Apply higher weight to tokens inside '<<' and '>>'\n",
    "        loss_weights = torch.ones_like(labels, dtype=torch.float)\n",
    "        loss_weights[inside_brackets_mask] = inside_brackets_weight\n",
    "\n",
    "        # Calculating weighted loss\n",
    "        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        weighted_loss = (loss * loss_weights.view(-1)).mean()\n",
    "\n",
    "        return weighted_loss\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Extract 'labels' and 'inside_brackets_mask' from inputs\n",
    "        labels = inputs.pop(\"labels\", None)\n",
    "        inside_brackets_mask = inputs.pop(\"inside_brackets_mask\", None)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs, labels=labels, inside_brackets_mask=inside_brackets_mask)\n",
    "\n",
    "        # Compute custom loss using the outputs and the labels\n",
    "        loss = outputs.loss if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxh6Oh9N2mKY"
   },
   "source": [
    "### debut de l'entrainement, définition des parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmwA-Yq0W1xu"
   },
   "outputs": [],
   "source": [
    "model_name = 't5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuoBUBfqNOZi"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "list_number = get_number_token(data_train)\n",
    "\n",
    "new_tokens = ['<<', '>>', 'wd:', 'wdt:', 'ps:', 'pq:']\n",
    "# Add these special tokens to the tokenizer\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "model = CustomT5Model.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Lfte2Da2u7T"
   },
   "source": [
    "### Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3320240,
     "status": "ok",
     "timestamp": 1700864449474,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "jz43RkD7DwS0",
    "outputId": "6ce99eb9-b457-4916-ecca-62912bd7e903"
   },
   "outputs": [],
   "source": [
    "\n",
    "# On crée 2 instances de CustomDataset : une pour le training et une pour la validation\n",
    "dataset = CustomDataset(data_train, tokenizer)\n",
    "eval_dataset=CustomDataset(data_validation, tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=2,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    save_steps=5000,\n",
    "    logging_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,  # Replace with your dataset\n",
    "    eval_dataset=eval_dataset,  # Replace with your eval dataset\n",
    ")\n",
    "\n",
    "# On commence l'entraînement\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5H46ELhDwS1"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer.save_pretrained(root+'t5_tokenizer_2_base_custom_retrained')\n",
    "#save the model\n",
    "model.save_pretrained(root+'t5_model_2_base_custom_retrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1700864454106,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "8nfIQP56yWdF",
    "outputId": "288816e8-c2ac-467a-b8e8-8d913ee3389a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(root+'t5_tokenizer_2_base_custom_retrained')\n",
    "# Define your special tokens\n",
    "\n",
    "# Add these special tokens to the tokenizer\n",
    "model = CustomT5Model.from_pretrained(root+'t5_model_2_base_custom_retrained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKQ5zfnY2-H0"
   },
   "source": [
    "## Scores sur l'ensemble de validation\n",
    "\n",
    "Définition des fonctions de métrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDMM2gjMDwS2"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, GenerationConfig, StoppingCriteriaList, LogitsProcessorList\n",
    "#model to cuda\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "def retrieve_back_tokenized(tokenizer : AutoTokenizer, tokenized):\n",
    "    return tokenizer.batch_decode(tokenized)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "def translate(model, tokenizer, dataset, max_new_tokens=210): #fonction pour générer la phrase output à partir de la phrase de base\n",
    "    model.eval()  # Evaluation mode\n",
    "    all_translated = []\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            # Adapted to use the new generate function\n",
    "            translated = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                generation_config=GenerationConfig(max_length=max_new_tokens),\n",
    "            )\n",
    "\n",
    "            # Retrieve tokenized translation\n",
    "            translated = retrieve_back_tokenized(tokenizer, translated)\n",
    "            all_translated += translated\n",
    "\n",
    "    return all_translated\n",
    "\n",
    "\n",
    "\n",
    "def extract_tags(prediction : pd.DataFrame, column_name : str):\n",
    "    #extrait les tags à l'aide de regex pour les comparer aux tags attendus\n",
    "    regex = \"<<\\s?(.[^>]*)>>\"\n",
    "    tags = []\n",
    "    for _, row in prediction.iterrows():\n",
    "        question = row[column_name]\n",
    "        tag_list = re.findall(regex,question)\n",
    "        new_tag_list = []\n",
    "        for tag in tag_list :\n",
    "          if 'wd:' in tag or 'wdt:' in tag or 'ps:' in tag or 'pq:' in tag :\n",
    "            tag = tag.split()\n",
    "            try :\n",
    "              tag = tag[0]+tag[1]\n",
    "            except :\n",
    "              tag = tag[0]\n",
    "          new_tag_list.append(tag)\n",
    "        tags.append(new_tag_list)\n",
    "    return tags\n",
    "\n",
    "\n",
    "def pad_missing_tags(df : pd.DataFrame):\n",
    "    #ajoute des tags vides manquants dans le cas ou trop ont été prédits ou pas assez\n",
    "    predict_tags = extract_tags(df, 'question_tagged_new')\n",
    "    wanted_tags = extract_tags(df, 'question_tagged')\n",
    "    new_predict_tags = []\n",
    "    for i in range(len(predict_tags)):\n",
    "        if len(predict_tags[i]) < len(wanted_tags[i]):\n",
    "            predict_tags[i] = predict_tags[i] + ['']*(len(wanted_tags[i])-len(predict_tags[i]))\n",
    "        elif len(predict_tags[i]) > len(wanted_tags[i]):\n",
    "            predict_tags[i] = predict_tags[i][:len(wanted_tags[i])]\n",
    "        new_predict_tags.append(predict_tags[i])\n",
    "\n",
    "    return new_predict_tags, wanted_tags\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def compute_accuracy(predict,true):\n",
    "\n",
    "    #flatten the list of list\n",
    "    predict = [item for sublist in predict for item in sublist]\n",
    "    true = [item for sublist in true for item in sublist]\n",
    "    return accuracy_score(true,predict)\n",
    "\n",
    "def compute_f1(predict,true):\n",
    "    #flatten the list of list\n",
    "    predict = [item for sublist in predict for item in sublist]\n",
    "    true = [item for sublist in true for item in sublist]\n",
    "    return f1_score(true,predict,average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iQrdu94DwS2"
   },
   "outputs": [],
   "source": [
    "# show what it gives on the validation set\n",
    "data_train = pd.read_csv(root+'train.csv',sep = '|')\n",
    "data_test = pd.read_csv(root+'test.csv', sep='|')\n",
    "data_validation = pd.read_csv(root+'validation.csv', sep ='|')\n",
    "dataset = CustomGenDataset(data_validation, tokenizer)\n",
    "data_validation['question_tagged_new'] = translate(model, tokenizer, dataset,max_new_tokens=200)\n",
    "data_validation['question_tagged_new'] = data_validation['question_tagged_new'].apply(lambda x: x.replace('<pad>',''))\n",
    "data_validation['question_tagged_new'] = data_validation['question_tagged_new'].apply(lambda x: x.replace('</s>',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1700944313822,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "qsiQxSrQDwS3",
    "outputId": "eb51f05f-5c45-4f48-81cd-702887f6d70a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     what is the<<wd: Q12140>> for<<wdt: P2175>> o...\n",
       "1     what is the<<pq: P2077>> for<<wd: Q633>> has<...\n",
       "2     what is<<wdt: P175>> of<<wdt: P156>> of<<wd: ...\n",
       "3               what is<<wdt: P2136>> of<<wd: Q1516>>?\n",
       "4     did<<wd: Q9194>><<wdt: P1269>><<wd: Q43229>> ...\n",
       "Name: question_tagged_new, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation['question_tagged_new'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioAn9H7z3oio"
   },
   "source": [
    "> il y a un probleme d'espace que nous corrigeons ulterieurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1700944313822,
     "user": {
      "displayName": "pierre cesar",
      "userId": "06990152005228481993"
     },
     "user_tz": 300
    },
    "id": "TBmoHPCEDwS3",
    "outputId": "fb53a294-f7d8-4688-b334-76119d040c11"
   },
   "outputs": [],
   "source": [
    "#performs scores\n",
    "predict_tags, wanted_tags = pad_missing_tags(data_validation)\n",
    "print(compute_accuracy(predict_tags, wanted_tags))\n",
    "print(compute_f1(predict_tags, wanted_tags))\n",
    "\n",
    "for predict, true in zip(predict_tags[:10], wanted_tags[:10]) :\n",
    "    print(predict)\n",
    "    print(true)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZoa-knA3ud-"
   },
   "source": [
    "> Le score f1 de 15% reste malgré tout en dessous de la Baseline attendue de 25% donnée sur le moodle"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb3f3ca36ac2f50d66e18d7677362432f7af6bbb1b03844778fb6db4c3043937"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
